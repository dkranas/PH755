{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Equations\n",
    "\n",
    "Ref: Computational Physics, Mark Newman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we are interested in finding solutions to equations of the form\n",
    "$$\n",
    "x\\, =\\, 2\\, -\\, e^{-x} \\\\\n",
    "x\\, =\\, \\frac{1}{2}\\,\\sin^{-1}(x\\,-\\,x^2)\\\\\n",
    "...\n",
    "$$\n",
    "\n",
    "Or in other words, we are interested in equations of the form $x\\, =\\, f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaxation Method\n",
    "\n",
    "Consider the equation $x\\, =\\, 2\\, -\\, e^{-x}$.\n",
    "\n",
    "In this method, the idea is to assume a value for $x$, iterate the equation several times until the value of $x$ converges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63212055883\n",
      "1.80448546585\n",
      "1.83544089392\n",
      "1.84045685534\n",
      "1.84125511391\n",
      "1.84138178281\n",
      "1.84140187354\n",
      "1.84140505985\n",
      "1.84140556519\n",
      "1.84140564533\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "x = 1.0 # first guess for x\n",
    "for k in range(10): # iterate the equation several times\n",
    "    x = 2. - exp(-x)\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the value of x settles down to the value $1.84140564533$. \n",
    "\n",
    "### Does relaxation method always work?\n",
    "\n",
    "1. The equation need not always come in the form $x\\, =\\, f(x)$. But in most cases one can rewrite the equation in this form. Eg:- Equation $\\log(x)\\, +x^2\\, -\\, 1\\, =\\, 0$ can be rewritten as\n",
    "$x\\, =\\, \\exp(1\\, -\\, x^2)$.\n",
    "\n",
    "2. An equation may have more than one solution. Relaxation method will sometimes gies one solution and sometimes give the other. The solution often depends on the starting value of $x$. \n",
    "\n",
    "3. There are some solutions to certain equations that are impossible to find. For example, consider the equation $x\\, =\\, e^{1\\, -\\, x^2}$. As one can see $x\\, =\\, 1$ is a solution. \n",
    "However, it is impossible to find this solution no matter how close we start to the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02009932499 0.9602106103 1.0811178843 0.844664408891 1.33181415133 0.461289738377 2.19726142311 0.0217539971468 2.71699574291 0.0016916246728 2.71827404985 0.00167991209709 2.71827415719 0.00167991111674 2.7182741572 0.00167991111666 2.7182741572 0.00167991111666 2.7182741572 0.00167991111666\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "x = 0.99 # first guess for x\n",
    "for k in range(20): # iterate the equation several times\n",
    "    x = exp(1. - x**2)\n",
    "    print x,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the solution oscillates back and forth between two solutions. A useful trick in cases like these is to rearrange the equation in an alternate way. Eg:- the above equation can be rewritten as $ x\\, =\\, \\sqrt{1\\, -\\, \\log x}$. In this form one can obtain the solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30120989105\n",
      "0.858315491489\n",
      "1.07367757795\n",
      "0.963799904409\n",
      "1.01826891043\n",
      "0.990906635926\n",
      "1.00455709697\n",
      "0.997724037577\n",
      "1.00113862994\n",
      "0.999430846935\n"
     ]
    }
   ],
   "source": [
    "from math import log, sqrt\n",
    "x = 0.5 # first guess for x\n",
    "for k in range(10): # iterate the equation several times\n",
    "    x = sqrt(1. - log(x))\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason behind success of relaxation method in finding a solution when we write the equation in one form and not in the other can be understood as follows.\n",
    "\n",
    "Suppose $x^*$ is the solution for $x\\, =\\, f(x)$. Let $x$ be the first guess and $x'$ be the value after first iteration, then\n",
    "$$\n",
    "x'\\, =\\, f(x)\\, =\\, f(x^*)\\, +\\, (x\\, -\\, x^*)\\,f'(x^*)\\, +\\, ...\n",
    "$$\n",
    "where I have Taylor expanded f(x) around $x^*$. \n",
    "\n",
    "Ignoring higher order terms, one can write\n",
    "\n",
    "$$\n",
    "x'\\, -\\, x^*\\, =\\, (x\\, -\\, x^*)\\,f'(x^*).\n",
    "$$\n",
    "\n",
    "This equation tells you that the new distance to the solution after iteration is equal to the distance to solution before iteration timems $f'(x^*)$. So, if $|f'(x^*)| < 1$, the distance to the solution decreases with each iteration and finally it converges to the solution. \n",
    "\n",
    "However, if $|f'(x^*)| \\gt 1$, the distance to solution keeps increasing and we never reach the solution. \n",
    "\n",
    "In our example, \n",
    "$$\n",
    "|f'(x^*)|\\, =\\, |\\frac{d\\, e^{x^2\\,-\\,1}}{d x}|_{x=1}\\, =\\, 2\n",
    "$$\n",
    "on the other hand \n",
    "$$\n",
    "|f'(x^*)|\\, =\\, |\\frac{d\\,\\sqrt{1\\, -\\, \\log x}}{d x}|_{x=1}\\, =\\, \\frac{1}{2}.\n",
    "$$\n",
    "This is why we are able to obtain a solution in one form and not the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to do when we do not get solution in one form?**\n",
    "\n",
    "Suppose solution does not converge in the form $x\\, =\\, f(x)$, one should try to solve the inverted equation. We can then use the inverted equation to obtain the solution. \n",
    "\n",
    "To see this, define $u\\, =\\, f^{-1}(x)$ so that $x\\, =\\, f(u)$. This implies,\n",
    "$$\n",
    "\\frac{d x}{d u}\\, =\\, f'(u) \\\\\n",
    "\\frac{d u}{d x}\\, =\\, \\frac{1}{f'(u)}.\n",
    "$$\n",
    "At $x\\, =\\, x^*$, we have $u\\, =\\, f^{-1}(x^*)\\, =\\, x^*$, *i.e.*\n",
    "$$\n",
    "\\frac{d u}{d x}\\, =\\, \\frac{1}{f'(x^*)}.\n",
    "$$\n",
    "Hence, if relaxation method fails to converge for $x\\, = \\, f(x)$, it will converge for $x\\, = \\, f^{-1}(x)$. \n",
    "\n",
    "Thus, if relaxation method fails for a particular equation, it would succeed for the inverted equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not all equations can be inverted**\n",
    "\n",
    "Eg:- if the function is a tenth order polynomial!\n",
    "\n",
    "In such cases, rearranging the equation works some times, other times it does not work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "Consider the equation $x = 1 - e^{-cx}$, where $c$ is a known\n",
    "parameter and $x$ is unknown.  This equation arises in a variety of\n",
    "situations, including the physics of contact processes, mathematical models\n",
    "of epidemics, and the theory of random graphs.\n",
    "\n",
    "1. Write a program to solve this equation for~$x$ using the relaxation\n",
    "  method for the case $c=2$.  Calculate your solution to an accuracy of at\n",
    "  least $10^{-6}$.\n",
    "2. Modify your program to calculate the solution for values of $c$ from\n",
    "  0 to 3 in steps of 0.01 and make a plot of $x$ as a function of~$c$.  You\n",
    "  should see a clear transition from a regime in which $x=0$ to a regime of\n",
    "  nonzero~$x$.  This is another example of a phase transition.  In physics\n",
    "  this transition is known as the *percolation transition*; in\n",
    "  epidemiology it is the *epidemic threshold*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaxation method for two or more variables\n",
    "\n",
    "Suppose we have $N$ equations of the form\n",
    "$$\n",
    "x_1\\, =\\, f_1(x_1, ..., x_N),\\\\\n",
    "\\vdots\\\\\n",
    "x_N\\, =\\, f_1(x_1, ..., x_N).\n",
    "$$\n",
    "To solve this system start with guesses for all variables, iterate until all the variables converge to a solution. \n",
    "\n",
    "*Caveat:* Not all systems will converge. Sometimes rearranging the system will help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search \n",
    "\n",
    "Binary search, also known as *bisection method*, is a more robust method than relaxation method. \n",
    "In this method, we try to find a solution within a given interval. If there is a solution in that interval, then this method will be able to find it. \n",
    "\n",
    "1. Consider an equation $f(x)\\,=\\,0$ in the interval $x\\, \\epsilon\\, [x_1,\\, x_2]$.\n",
    "\n",
    "2. If $f(x_1)<0$ and $f(x_2)>0$ , then as long as $f(x)$ is continuous, there must be a solution between $x_1$ and $x_2$.\n",
    "\n",
    "3. Now take a new point $x'\\, =\\, (x_1\\, +\\, x_2)/2$ half way between $x_1$ and $x_2$. Suppose $f(x')>0$, this means that solution lies between $x_1$ and $x'$. Hence one can replace $x_2$ by $x'$. If $f(x')<0$, then one should replace $x_1$ by $x'$. \n",
    "\n",
    "4. Repeat the process to narrow down the window. If we want the solution with an accuracy of $10^{-6}$ or less, then continue the process till $|x_1\\,-\\,x_2| < 10^{-6}$.\n",
    "\n",
    "\n",
    "If $\\Delta\\, =\\, |x_1\\,-\\,x_2|$, then with each step the size of the interval gets halved. Thus after $N$ steps, the size of interval is $\\Delta/2^N$. If $\\epsilon$ is the required accuracy, \n",
    "the number of required steps is given by the expression $\\Delta/2^N\\, =\\, \\epsilon$, or \n",
    "$$\n",
    "N\\, =\\, \\log_2 \\frac{\\Delta}{\\epsilon}\n",
    "$$\n",
    "\n",
    "Since logarithm is a very slowly varying function, even if $\\Delta$ is large $N$ will be small. \n",
    "Eg:- If $\\Delta\\, =\\, 10^{10}$ and $\\epsilon\\, =\\, 10^{-10}$ we obtain \n",
    "$$\n",
    "N\\, =\\, \\log_2 \\frac{10^{10}}{10^{-10}}\\, \\simeq\\, 66.43\\ldots\n",
    "$$\n",
    "which can be quickly done.\n",
    "\n",
    "![](250px-Bisection_method.svg.png)\n",
    "\n",
    "Figure shows a few steps of the bisection method applied over the starting range [a1;b1]. The bigger red dot is the root of the function. (Source : Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages:**\n",
    "\n",
    "1. There should be a root in the interval $[x_1,\\,x_2]$.\n",
    "\n",
    "2. It doesn't work if there are even number of solutions in the interval. In this case both $f(x_1)$ and $f(x_2)$ will have same signs. \n",
    "\n",
    "\n",
    "There is no clear method of identifying the interval. Your knowledge of the function can be of help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :**\n",
    "\n",
    "Planck's radiation law tells us that the intensity of radiation per unit area and per unit wavelength~$\\lambda$ from a black body at temperature~$T$~is \n",
    "$$\n",
    "  I(\\lambda) = \\frac{2\\pi hc^2\\lambda^{-5}}{e^{hc/\\lambda k_BT}-1}\\,,\n",
    "$$\n",
    "where $h$~is Planck's constant, $c$~is the speed of light, and $k_B$ is Boltzmann's constant.\n",
    "\n",
    "1. Show by differentiating that the wavelength~$\\lambda$ at which the\n",
    "  emitted radiation is strongest is the solution of the equation\n",
    "$$\n",
    "5 e^{-hc/\\lambda k_BT} + {hc\\over\\lambda k_BT} - 5 = 0.\n",
    "$$\n",
    "Make the substitution $x=hc/\\lambda k_BT$ and hence show that the\n",
    "wavelength of maximum radiation obeys the *Wien displacement law*:\n",
    "$$\n",
    "\\lambda = {b\\over T}\\,,\n",
    "$$\n",
    "where the so-called *Wien displacement constant* is $b=hc/k_Bx$, and\n",
    "$x$ is the solution to the nonlinear equation\n",
    "$$\n",
    "5 e^{-x} + x - 5 = 0.\n",
    "$$\n",
    "\n",
    "2. Write a program to solve this equation to an accuracy\n",
    "  of~$\\epsilon=10^{-6}$ using the binary search method, and hence find a\n",
    "  value for the displacement constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method\n",
    "\n",
    "Also known as **Newton-Raphson method**. Here also our goal is to find the root of a function $f(x)$, *i.e.* $f(x)\\,=\\,0$.\n",
    "\n",
    "![](newtonsmethod_mn.png)\n",
    "\n",
    "Source: Mark Newman's book\n",
    "\n",
    "![](newtonRaphsonMethod.png)\n",
    "\n",
    "Source : https://media.geeksforgeeks.org/wp-content/cdn-uploads/newtonRaphsonMethod.png\n",
    "\n",
    "1. Let x be the starting point.\n",
    "\n",
    "2. Find slope at x and compute the $x$-intercept. \n",
    "Slope is given by\n",
    "$$\n",
    "f'(x)\\, =\\, \\frac{f(x)}{\\Delta x}\n",
    "$$\n",
    "Then the new point is given by,\n",
    "$$\n",
    "x'\\, =\\, x\\, -\\, \\Delta\\,x\\, =\\, x\\, -\\, \\frac{f(x)}{f'(x)}.\n",
    "$$\n",
    "\n",
    "3. Repeat step 2 until the solution converges.\n",
    "\n",
    "In order to use this method, one needs to know the derivative of the function. Does not converge for all functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution is x = 0.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function whose root is required.\n",
    "def f(x):\n",
    "    return np.tanh(x) - 0.6\n",
    "\n",
    "# Newton-Raphson method\n",
    "\n",
    "x = 0. # Starting point\n",
    "eps = 1.e-6 #Accuracy\n",
    "delta = 1.\n",
    "while (np.abs(delta) > eps):\n",
    "    delta = f(x)*np.cosh(x)**2 #compute delta\n",
    "    x-=delta # find new x\n",
    "print \"solution is x =\",x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The actual solution is\n",
    "np.arctanh(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Secant method\n",
    "\n",
    "Newton's method required analytical form of derivative of $f(x)$. If we do not know the analytical form, we can use Secant method. \n",
    "In this method, \n",
    "\n",
    "1. Consider two points $x_1$ and $x_2$, the solution need not be between the two points. \n",
    "\n",
    "2. We now calculate an approximation to the derivative of $f$ at $x_2$ from the formula\n",
    "$$\n",
    "f'(x_2)\\, \\simeq\\, \\frac{f(x_2)\\, -\\, f(x_1)}{x_2\\, -\\, x_1}.\n",
    "$$\n",
    "\n",
    "3. We substitute the value to get to the next point $x_3$\n",
    "$$\n",
    "x_3\\, =\\, x_2\\, -\\, f(x_2)\\, \\frac{x_2\\, -\\, x_1}{f(x_2)\\, -\\, f(x_1)}.\n",
    "$$\n",
    "\n",
    "4. Use the value of $f$ at $x_3$ and $x_{2}$ to find $x_{4}$ and so on until the series of numbers converges.\n",
    "\n",
    "This method can also be generalized to solve simulatneous nonlinear equations of $N$ variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima and Minima of Functions\n",
    "\n",
    "![](1200px-Extrema_example_original.svg.png)\n",
    "\n",
    "Minimum arise in various contexts in Physics. Eg:- equilibrium point of a system is given by minimum of potential energy. \n",
    "in variational method for solving quantum mechanics problems etc. \n",
    "\n",
    "To find a minimum of a function $f(x_1,\\, x_2,\\ldots)$, take partial derivatives with respect to each variable, set them to zero and solve them as simultaneous equations. *i.e.* Solve simultaneously\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_i}\\, =\\, 0\\;\\;\\; {\\rm for\\, all}\\, i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden Ratio Search\n",
    "\n",
    "It is a good method to find minimum of a function of single variable. \n",
    "\n",
    "![](goldenratio.png)\n",
    "\n",
    "Consider four points $x_1$, $x_2$, $x_3$ and $x_4$ as in the figure. \n",
    "Suppose that atleast one of the values $f(x_2)$ and $f(x_3)$ at the two interior points is smaller than the values $f(x_1)$ and $f(x_4)$ at two outer points. Then the minimum lies between $x_1$ and $x_3$.  \n",
    "Then we choose another point in between $x_1$ and $x_3$ and continue the procedure until the interval is small enough.\n",
    "\n",
    "Golden ratio search can be implemented as follows.\n",
    "\n",
    "1. Choose two points $x_1$ and $x_4$ such that a minimum exists between the two points. \n",
    "\n",
    "2. Choose two points $x_2$ and $x_3$ interior to $x_1$ and $x_4$ such that they are located symmetrically *i.e.*\n",
    "\n",
    "$$\n",
    "x_2\\, -\\, x_1\\, =\\, x_4\\, -\\, x_3.\n",
    "$$\n",
    "\n",
    "3. This does not fix the location of two interior points $x_2$ and $x_3$. Their position should be chosen so that in each step the size of the interval decreases by the largest amount. \n",
    "\n",
    "      a. If we choose these points very close to the centre, then the interval reduction in this step will be large. However, in the next iteration the decrease in the step will be small. \n",
    "      \n",
    "      b. If we choose the two points closer to the edges, reduction in interval will be less in this step. \n",
    "\n",
    "4. Let us define z to be the ratio between the width of the bracketing interval before and after the step of the search process. If we suppose that the minimum falls in the left-hand part of the interval, between $x_1$ and $x_3$, then we have \n",
    "\n",
    "$$\n",
    "z\\, =\\, \\frac{x_4\\, -\\, x_1}{x_3\\,-\\,x_1}\\, =\\, \\frac{x_2\\,-\\,x_1\\,+x_3\\,-\\,x_1}{x_3\\,-\\,x_1}\n",
    "$$\n",
    "\n",
    "which simplifies to\n",
    "\n",
    "$$\n",
    "z\\, =\\, \\frac{x_2\\,-\\,x_1}{x_3\\,-\\,x_1}\\,+\\,1.\n",
    "$$\n",
    "\n",
    "For the next step, from figure,\n",
    "\n",
    "$$\n",
    "z\\, =\\, \\frac{x_3\\,-\\,x_1}{x_2\\,-\\,x_1}\n",
    "$$\n",
    "\n",
    "Substituting this to previous expression for z, we obtain\n",
    "\n",
    "$$\n",
    "z^2\\,-\\,z\\,-\\,1\\,=0\n",
    "$$\n",
    "\n",
    "which has the solution $z\\, =\\, \\frac{1\\,+\\,\\sqrt{5}}{2}\\, =\\, 1.618 \\ldots$. This value is known as *golden ratio*. \n",
    "The value of $z$ fixes the position of two interior points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Golden ratio search goes as follows:**\n",
    "\n",
    "1. Choose two initial outside points $x_1$ and $x_4$, evaluate $x_2$ and $x_3$ using golden ratio rule. Evaluate $f(x)$ at each point. Choose the required accuracy. \n",
    "\n",
    "2. If $f(x_2) < f(x_3)$ then the minimum lies between $x_1$ and $x_3$. In this case $x_3$ becomes the new $x_4$, $x_2$ becomes new $x_3$ and the new $x_2$ is chosen according to golden ratio rule. Evaluate $f(x)$ at this point.\n",
    "\n",
    "3. Other wise it lies between $x_2$ and $x_4$. In this case $x_2$ become the new  $x_1$, $x_3$ becomes new $x_2$ and new value of $x_3$ has to be determined. Evaluate $f(x)$ at this point.\n",
    "\n",
    "4. If $x_4\\, -\\, x_1$ is greater than required accuracy, repeat from step two. Else, $(x_2\\,+\\,x_3)/2$ is the final estimate of the position of minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Newton Method \n",
    "\n",
    "1. Finding minima and maxima is equal to finding roots of equation $f'(x)\\,=0$.\n",
    "\n",
    "2. Then one can apply Newton's method to the above equation, *i.e.* \n",
    "$$\n",
    "x'\\, =\\, x\\, -\\, \\frac{f'(x)}{f''(x)}.\n",
    "$$\n",
    "where we have replaced $f(x)$ by $f'(x)$.\n",
    "\n",
    "3. Starting with a value of $x$, one can iterate the above equation until it converges to a solution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "In many cases one will not know the second derivative of the function. In such cases, \n",
    "one can write the above equation as \n",
    "$$\n",
    "x'\\, =\\, x\\,-\\, \\gamma f'(x)\n",
    "$$\n",
    "where $\\gamma$ is a constant value that represents a rough guess at 1/f''(x). \n",
    "The method works even if $\\gamma$ is only of the right order of magnitude. \n",
    "This method is known as **gradient descent**. \n",
    "This method is called so as it comutes the gradient of the function at the point x and then subtracts a constant times that gradient from the value of $x$. If $\\gamma$ is positive, the method will move \"down hill\" from $x$ to $x'$ and converge towards the minimum of the function. For negative $\\gamma$ it will converge to the maximum. \n",
    "$\\gamma$ is chosen using trial and error.\n",
    "\n",
    "In some cases, even the first derivative is not known. In such cases, one should start with two points $x_1$ and $x_2$ and use them to find slope at $x_2$ using \n",
    "$$\n",
    "f'(x)\\, \\simeq\\, \\frac{f(x_2)\\, -\\, f(x_1)}{x_2\\,-\\,x_1}\n",
    "$$\n",
    "and the next estimate is gven by \n",
    "$$\n",
    "x_3\\, =\\, x_2\\, -\\, \\gamma\\,\\frac{f(x_2)\\,-\\,f(x_1)}{x_2\\,-\\,x_1}\n",
    "$$\n",
    "and so on. \n",
    "\n",
    "Gradient Descent has application in **machine learning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
